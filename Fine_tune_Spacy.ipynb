{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Is Sirius visible tonight?', {'entities': [(3, 9, 'CELESTIAL_OBJECT')]})\n",
      "('Find the position of sirius.', {'entities': [(21, 27, 'CELESTIAL_OBJECT')]})\n",
      "('What are the coordinates of Canopus?', {'entities': [(28, 35, 'CELESTIAL_OBJECT')]})\n",
      "('Astronomers often observe canopus.', {'entities': [(26, 33, 'CELESTIAL_OBJECT')]})\n",
      "('Show me Rigil Kentaurus in the sky.', {'entities': [(8, 23, 'CELESTIAL_OBJECT')]})\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# List of stars and planets\n",
    "stars = [\n",
    "    \"Sirius\", \"Canopus\", \"Rigil Kentaurus\", \"Arcturus\", \"Vega\", \"Capella\", \"Rigel\",\n",
    "    \"Procyon\", \"Achernar\", \"Betelgeuse\", \"Hadar\", \"Altair\", \"Aldebaran\", \"Spica\", \n",
    "    \"Antares\", \"Pollux\", \"Fomalhaut\", \"Deneb\", \"Mimosa\", \"Regulus\", \"Adhara\", \n",
    "    \"Shaula\", \"Castor\", \"Gacrux\", \"Bellatrix\", \"Alnilam\", \"Alnair\", \"Alnitak\", \n",
    "    \"Eta Carinae\", \"Alphard\", \"Algol\", \"Dubhe\", \"Wezen\", \"Sargas\", \"Alhena\", \n",
    "    \"Kaus Australis\", \"Peacock\", \"Atria\", \"Markab\", \"Alcor\", \"Menkalinan\", \"Mirfak\",\n",
    "    \"Gienah\", \"Acrux\", \"Alcyone\", \"Pherkad\", \"Maia\", \"Menkent\", \"Merak\", \"Dschubba\", \n",
    "    \"Zeta Reticuli\", \"Izar\", \"Zubenelgenubi\", \"Denebola\", \"Mintaka\", \"Caph\", \"Arctans\",\n",
    "    \"Enif\", \"Ruchbah\", \"Shedar\", \"Scheat\", \"Sualocin\", \"Tarazed\", \"Ankaa\", \"Nunki\",\n",
    "    \"Mirzam\", \"Saiph\", \"Hamal\", \"Acamar\", \"Phecda\", \"Baten Kaitos\", \"Almach\", \"Kochab\",\n",
    "    \"Navi\", \"Unukalhai\", \"Sabik\", \"Tiaki\", \"Furud\", \"Aldhibah\", \"Mira\", \"Castula\",\n",
    "    \"Tureis\", \"Maia\", \"Merope\", \"Sterope\", \"Atlas\", \"Pleione\", \"Electra\", \"Celaeno\", \n",
    "    \"Taygeta\", \"Alpheratz\", \"Rasalhague\", \"Rastaban\", \"Muphrid\", \"Kornephoros\", \n",
    "    \"Sadalmelik\", \"Venus\", \"Mars\", \"Jupiter\", \"Saturn\", \"Uranus\", \"Neptune\", \"Pluto\"\n",
    "]\n",
    "\n",
    "# List of sentence templates\n",
    "sentence_templates = [\n",
    "    \"Point the telescope at {}.\",\n",
    "    \"Show me {} in the sky.\",\n",
    "    \"Where is {} located?\",\n",
    "    \"Find the position of {}.\",\n",
    "    \"What are the coordinates of {}?\",\n",
    "    \"{} is one of the brightest stars.\",\n",
    "    \"Can you locate {}?\",\n",
    "    \"Is {} visible tonight?\",\n",
    "    \"We need to find {}.\",\n",
    "    \"The star {} is quite famous.\",\n",
    "    \"Astronomers often observe {}.\"\n",
    "]\n",
    "\n",
    "# Function to generate training data with lowercase augmentation\n",
    "def generate_training_data(star_list, template_list):\n",
    "    train_data = []\n",
    "    for star in star_list:\n",
    "        # Create both title case and lowercase versions of the sentences\n",
    "        for case_type in [star, star.lower()]:\n",
    "            sentence_template = random.choice(template_list)\n",
    "            sentence = sentence_template.format(case_type)\n",
    "            start_idx = sentence.index(case_type)\n",
    "            end_idx = start_idx + len(case_type)\n",
    "            train_data.append((sentence, {\"entities\": [(start_idx, end_idx, \"CELESTIAL_OBJECT\")]}))\n",
    "    return train_data\n",
    "\n",
    "# Generate the training data with lowercase augmentation\n",
    "train_data = generate_training_data(stars, sentence_templates)\n",
    "\n",
    "# Check the first 5 examples\n",
    "for entry in train_data[:5]:\n",
    "    print(entry)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the training data to a pickle file\n",
    "with open(\"train_data.pkl\", \"wb\") as f:\n",
    "    pickle.dump(train_data, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.training import Example\n",
    "\n",
    "# Load the small English model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Get the pipeline component (NER)\n",
    "ner = nlp.get_pipe(\"ner\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner.add_label(\"CELESTIAL_OBJECT\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_exceptions = [\"ner\"]\n",
    "unaffected_pipes = [pipe for pipe in nlp.pipe_names if pipe not in pipe_exceptions]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = []\n",
    "for text, annotations in train_data:\n",
    "    doc = nlp.make_doc(text)\n",
    "    example = Example.from_dict(doc, annotations)\n",
    "    examples.append(example)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Losses: {'ner': np.float32(315.90884)}\n",
      "Iteration 1, Losses: {'ner': np.float32(113.98766)}\n",
      "Iteration 2, Losses: {'ner': np.float32(57.23144)}\n",
      "Iteration 3, Losses: {'ner': np.float32(40.25379)}\n",
      "Iteration 4, Losses: {'ner': np.float32(28.831171)}\n",
      "Iteration 5, Losses: {'ner': np.float32(31.551624)}\n",
      "Iteration 6, Losses: {'ner': np.float32(22.636852)}\n",
      "Iteration 7, Losses: {'ner': np.float32(13.427785)}\n",
      "Iteration 8, Losses: {'ner': np.float32(6.9583025)}\n",
      "Iteration 9, Losses: {'ner': np.float32(3.2288153)}\n",
      "Iteration 10, Losses: {'ner': np.float32(8.250778)}\n",
      "Iteration 11, Losses: {'ner': np.float32(0.01729602)}\n",
      "Iteration 12, Losses: {'ner': np.float32(4.8855643)}\n",
      "Iteration 13, Losses: {'ner': np.float32(0.76181114)}\n",
      "Iteration 14, Losses: {'ner': np.float32(1.6894152)}\n",
      "Iteration 15, Losses: {'ner': np.float32(0.06056088)}\n",
      "Iteration 16, Losses: {'ner': np.float32(0.8324091)}\n",
      "Iteration 17, Losses: {'ner': np.float32(0.09921158)}\n",
      "Iteration 18, Losses: {'ner': np.float32(6.382583)}\n",
      "Iteration 19, Losses: {'ner': np.float32(5.575686)}\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from spacy.util import minibatch, compounding\n",
    "\n",
    "# Start training\n",
    "with nlp.disable_pipes(*unaffected_pipes):  # Only train NER\n",
    "    optimizer = nlp.resume_training()\n",
    "    for itn in range(20):  # Number of iterations\n",
    "        random.shuffle(examples)\n",
    "        losses = {}\n",
    "        batches = minibatch(examples, size=compounding(4.0, 32.0, 1.001))\n",
    "        for batch in batches:\n",
    "            nlp.update(batch, drop=0.5, losses=losses)\n",
    "        print(f\"Iteration {itn}, Losses: {losses}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Betelgeuse CELESTIAL_OBJECT\n"
     ]
    }
   ],
   "source": [
    "# Test the custom model\n",
    "doc = nlp(\"Betelgeuse is a red supergiant star.\")\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "nlp.to_disk(\"custom_celestial_ner\")\n",
    "\n",
    "# Load the saved model later\n",
    "nlp_custom = spacy.load(\"custom_celestial_ner\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
