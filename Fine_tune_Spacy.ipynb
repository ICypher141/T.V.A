{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Find the position of Sirius.', {'entities': [(21, 27, 'CELESTIAL_OBJECT')]})\n",
      "('The star sirius is quite famous.', {'entities': [(9, 15, 'CELESTIAL_OBJECT')]})\n",
      "('Point the telescope at Canopus.', {'entities': [(23, 30, 'CELESTIAL_OBJECT')]})\n",
      "('What are the coordinates of canopus?', {'entities': [(28, 35, 'CELESTIAL_OBJECT')]})\n",
      "('Show me Rigil Kentaurus in the sky.', {'entities': [(8, 23, 'CELESTIAL_OBJECT')]})\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# List of stars and planets\n",
    "stars = [\n",
    "    \"Sirius\", \"Canopus\", \"Rigil Kentaurus\", \"Arcturus\", \"Vega\", \"Capella\", \"Rigel\",\n",
    "    \"Procyon\", \"Achernar\", \"Betelgeuse\", \"Hadar\", \"Altair\", \"Aldebaran\", \"Spica\", \n",
    "    \"Antares\", \"Pollux\", \"Fomalhaut\", \"Deneb\", \"Mimosa\", \"Regulus\", \"Adhara\", \n",
    "    \"Shaula\", \"Castor\", \"Gacrux\", \"Bellatrix\", \"Alnilam\", \"Alnair\", \"Alnitak\", \n",
    "    \"Eta Carinae\", \"Alphard\", \"Algol\", \"Dubhe\", \"Wezen\", \"Sargas\", \"Alhena\", \n",
    "    \"Kaus Australis\", \"Peacock\", \"Atria\", \"Markab\", \"Alcor\", \"Menkalinan\", \"Mirfak\",\n",
    "    \"Gienah\", \"Acrux\", \"Alcyone\", \"Pherkad\", \"Maia\", \"Menkent\", \"Merak\", \"Dschubba\", \n",
    "    \"Zeta Reticuli\", \"Izar\", \"Zubenelgenubi\", \"Denebola\", \"Mintaka\", \"Caph\", \"Arctans\",\n",
    "    \"Enif\", \"Ruchbah\", \"Shedar\", \"Scheat\", \"Sualocin\", \"Tarazed\", \"Ankaa\", \"Nunki\",\n",
    "    \"Mirzam\", \"Saiph\", \"Hamal\", \"Acamar\", \"Phecda\", \"Baten Kaitos\", \"Almach\", \"Kochab\",\n",
    "    \"Navi\", \"Unukalhai\", \"Sabik\", \"Tiaki\", \"Furud\", \"Aldhibah\", \"Mira\", \"Castula\",\n",
    "    \"Tureis\", \"Maia\", \"Merope\", \"Sterope\", \"Atlas\", \"Pleione\", \"Electra\", \"Celaeno\", \n",
    "    \"Taygeta\", \"Alpheratz\", \"Rasalhague\", \"Rastaban\", \"Muphrid\", \"Kornephoros\", \n",
    "    \"Sadalmelik\", \"Venus\", \"Mars\", \"Jupiter\", \"Saturn\", \"Uranus\", \"Neptune\", \"Pluto\",\n",
    "    \"M1\", \"M2\", \"M3\", \"M4\", \"M5\", \"M6\", \"M7\", \"M8\", \"M9\", \"M10\", \"M11\", \"M12\", \"M13\",\n",
    "    \"M14\", \"M15\", \"M16\", \"M17\", \"M18\", \"M19\", \"M20\", \"M21\", \"M22\", \"M23\", \"M24\",\n",
    "    \"M25\", \"M26\", \"M27\", \"M28\", \"M29\", \"M30\", \"M31\", \"M32\", \"M33\", \"M34\", \"M35\",\n",
    "    \"M36\", \"M37\", \"M38\", \"M39\", \"M40\", \"M41\", \"M42\", \"M43\", \"M44\", \"M45\", \"M46\",\n",
    "    \"M47\", \"M48\", \"M49\", \"M50\", \"M51\", \"M52\", \"M53\", \"M54\", \"M55\", \"M56\", \"M57\",\n",
    "    \"M58\", \"M59\", \"M60\", \"M61\", \"M62\", \"M63\", \"M64\", \"M65\", \"M66\", \"M67\", \"M68\",\n",
    "    \"M69\", \"M70\", \"M71\", \"M72\", \"M73\", \"M74\", \"M75\", \"M76\", \"M77\", \"M78\", \"M79\",\n",
    "    \"M80\", \"M81\", \"M82\", \"M83\", \"M84\", \"M85\", \"M86\", \"M87\", \"M88\", \"M89\", \"M90\",\n",
    "    \"M91\", \"M92\", \"M93\", \"M94\", \"M95\", \"M96\", \"M97\", \"M98\", \"M99\", \"M100\", \"M101\",\n",
    "    \"M102\", \"M103\", \"M104\", \"M105\", \"M106\", \"M107\", \"M108\", \"M109\", \"M110\", \"NGC 1\",\"NGC 2\",\"NGC 4\",\"NGC 5\"\n",
    "]\n",
    "\n",
    "# List of sentence templates\n",
    "sentence_templates = [\n",
    "    \"Point the telescope at {}.\",\n",
    "    \"Show me {} in the sky.\",\n",
    "    \"Where is {} located?\",\n",
    "    \"Find the position of {}.\",\n",
    "    \"What are the coordinates of {}?\",\n",
    "    \"{} is one of the brightest stars.\",\n",
    "    \"Can you locate {}?\",\n",
    "    \"Is {} visible tonight?\",\n",
    "    \"We need to find {}.\",\n",
    "    \"The star {} is quite famous.\",\n",
    "    \"Astronomers often observe {}.\"\n",
    "]\n",
    "\n",
    "# Function to generate training data with lowercase augmentation\n",
    "def generate_training_data(star_list, template_list):\n",
    "    train_data = []\n",
    "    for star in star_list:\n",
    "        # Create both title case and lowercase versions of the sentences\n",
    "        for case_type in [star, star.lower()]:\n",
    "            sentence_template = random.choice(template_list)\n",
    "            sentence = sentence_template.format(case_type)\n",
    "            start_idx = sentence.index(case_type)\n",
    "            end_idx = start_idx + len(case_type)\n",
    "            train_data.append((sentence, {\"entities\": [(start_idx, end_idx, \"CELESTIAL_OBJECT\")]}))\n",
    "    return train_data\n",
    "\n",
    "# Generate the training data with lowercase augmentation\n",
    "train_data = generate_training_data(stars, sentence_templates)\n",
    "\n",
    "# Check the first 5 examples\n",
    "for entry in train_data[:5]:\n",
    "    print(entry)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the training data to a pickle file\n",
    "with open(\"train_data.pkl\", \"wb\") as f:\n",
    "    pickle.dump(train_data, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.training import Example\n",
    "\n",
    "# Load the small English model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Get the pipeline component (NER)\n",
    "ner = nlp.get_pipe(\"ner\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner.add_label(\"CELESTIAL_OBJECT\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_exceptions = [\"ner\"]\n",
    "unaffected_pipes = [pipe for pipe in nlp.pipe_names if pipe not in pipe_exceptions]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = []\n",
    "for text, annotations in train_data:\n",
    "    doc = nlp.make_doc(text)\n",
    "    example = Example.from_dict(doc, annotations)\n",
    "    examples.append(example)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Losses: {'ner': np.float32(402.44385)}\n",
      "Iteration 1, Losses: {'ner': np.float32(76.43892)}\n",
      "Iteration 2, Losses: {'ner': np.float32(60.63463)}\n",
      "Iteration 3, Losses: {'ner': np.float32(49.31287)}\n",
      "Iteration 4, Losses: {'ner': np.float32(25.782892)}\n",
      "Iteration 5, Losses: {'ner': np.float32(6.3486433)}\n",
      "Iteration 6, Losses: {'ner': np.float32(2.4234555)}\n",
      "Iteration 7, Losses: {'ner': np.float32(4.776085)}\n",
      "Iteration 8, Losses: {'ner': np.float32(0.957246)}\n",
      "Iteration 9, Losses: {'ner': np.float32(9.163038)}\n",
      "Iteration 10, Losses: {'ner': np.float32(4.251299)}\n",
      "Iteration 11, Losses: {'ner': np.float32(1.3565184)}\n",
      "Iteration 12, Losses: {'ner': np.float32(1.7081311)}\n",
      "Iteration 13, Losses: {'ner': np.float32(3.484655)}\n",
      "Iteration 14, Losses: {'ner': np.float32(0.67460865)}\n",
      "Iteration 15, Losses: {'ner': np.float32(2.105983)}\n",
      "Iteration 16, Losses: {'ner': np.float32(0.00012206755)}\n",
      "Iteration 17, Losses: {'ner': np.float32(0.004250537)}\n",
      "Iteration 18, Losses: {'ner': np.float32(0.14419526)}\n",
      "Iteration 19, Losses: {'ner': np.float32(0.0064382884)}\n",
      "Iteration 20, Losses: {'ner': np.float32(2.9809418)}\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from spacy.util import minibatch, compounding\n",
    "\n",
    "# Start training\n",
    "with nlp.disable_pipes(*unaffected_pipes):  # Only train NER\n",
    "    optimizer = nlp.resume_training()\n",
    "    for itn in range(21):  # Number of iterations\n",
    "        random.shuffle(examples)\n",
    "        losses = {}\n",
    "        batches = minibatch(examples, size=compounding(4.0, 32.0, 1.001))\n",
    "        for batch in batches:\n",
    "            nlp.update(batch, drop=0.5, losses=losses)\n",
    "        print(f\"Iteration {itn}, Losses: {losses}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NGC 13 CELESTIAL_OBJECT\n",
      "star CELESTIAL_OBJECT\n"
     ]
    }
   ],
   "source": [
    "# Test the custom model\n",
    "doc = nlp(\"NGC 13 is a red supergiant star.\")\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "nlp.to_disk(\"custom_celestial_ner\")\n",
    "\n",
    "# Load the saved model later\n",
    "nlp_custom = spacy.load(\"custom_celestial_ner\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
